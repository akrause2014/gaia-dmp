#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Set up a test deployment so that we can check that changes to the table
        schema in the gaiadmpsetup library work with the new mount of DR3.

    Result:

        Work in progress ...
        Got diverted by error messages generated by the tests.

            parse errors generated by testall
            https://github.com/wfau/gaia-dmp/issues/1120

            ERROR messages in the zeppelin-interpreter-spark logs.
            https://github.com/wfau/gaia-dmp/issues/1121


# -----------------------------------------------------
# Check which cloud is currently live.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Thu  9 Feb 12:03:20 UTC 2023
    >   iris-gaia-red-20230125-zeppelin


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    #
    # Live is red, selecting blue for the deployment.
    #

    source "${HOME:?}/aglais.env"

    agcolour=blue
    configname=zeppelin-54.86-spark-6.26.43

    agproxymap=3000:3000
    clientname=ansibler-${agcolour}
    cloudname=iris-gaia-${agcolour}

    podman run \
        --rm \
        --tty \
        --interactive \
        --name     "${clientname:?}" \
        --hostname "${clientname:?}" \
        --publish  "${agproxymap:?}" \
        --env "cloudname=${cloudname:?}" \
        --env "configname=${configname:?}" \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK:?}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        ghcr.io/wfau/atolmis/ansible-client:2022.07.25 \
        bash

    >   ....
    >   ....


# -----------------------------------------------------
# Deploy everything.
#[root@ansibler]

    time \
        source /deployments/hadoop-yarn/bin/deploy.sh

    >   ....
    >   ....
    >   aglais:
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         conf: zeppelin-54.86-spark-6.26.43
    >         name: iris-gaia-blue-20230209
    >         date: 20230209T120757
    >         hostname: zeppelin.gaia-dmp.uk
    >     spec:
    >       openstack:
    >         cloud:
    >           base: arcus
    >           name: iris-gaia-blue

    >   real    118m26.551s
    >   user    27m55.173s
    >   sys     6m11.315s


# -----------------------------------------------------
# Create a test user.
#[root@ansibler]

    source /deployments/zeppelin/bin/create-user-tools.sh

    username=$(pwgen 16 1)

    createusermain "${username}" \
    | tee "/tmp/${username}.json" \
    | jq '.shirouser | {"username": .name, "password": .password}'

    password=$(
        jq -r '.shirouser.password' "/tmp/${username}.json"
        )

    >   {
    >     "username": "oovah5aiN9te6Cha",
    >     "password": "...."
    >   }


# -----------------------------------------------------
# Setup a SSH tunnel.
# https://linux.die.net/man/1/ssh
#[root@ansibler]

    ssh \
        -n \
        -f \
        -N \
        -L 8080:zeppelin:8080 \
        zeppelin

    zeppelinurl='http://localhost:8080'


# -----------------------------------------------------
# Run all the test user's examples.
#[root@ansibler]

    source /deployments/zeppelin/bin/zeppelin-rest-tools.sh

    testall \
        "${username:?}" \
        "${password:?}" \
    | tee "/tmp/${username}-testall.json" \
    | jq '.'

    >   parse error: Invalid numeric literal at line 1, column 83
    >   parse error: Invalid numeric literal at line 1, column 83
    >   parse error: Invalid numeric literal at line 1, column 83
    >   {
    >     "login": {
    >       "status": "OK",
    >       "message": "",
    >       "body": {
    >         "principal": "oovah5aiN9te6Cha",
    >         "ticket": "de0f3e73-61dd-4ba4-afa5-5087bf7b3741",
    >         "roles": "[]"
    >       }
    >     },
    >     "notebooks": [
    >       {
    >         "noteid": "2HT2SB47R",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HT2SB47R",
    >           "name": "1. Start here",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/1. Start here",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:0:40"
    >         }
    >       },
    >       {
    >         "noteid": "2HU6JV98Y",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HU6JV98Y",
    >           "name": "2. Data holdings",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/2. Data holdings",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:0:12"
    >         }
    >       },
    >       {
    >         "noteid": "2HTQX92GX",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HTQX92GX",
    >           "name": "3. Source counts over the sky",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/3. Source counts over the sky",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:0:36"
    >         }
    >       },
    >       {
    >         "noteid": "2HUB87DQH",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HUB87DQH",
    >           "name": "4. Mean proper motions over the sky",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/4. Mean proper motions over the sky",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:0:55"
    >         }
    >       },
    >       {
    >         "noteid": "2HRE6YPG8",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HRE6YPG8",
    >           "name": "5. Working with Gaia XP spectra",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/5. Working with Gaia XP spectra",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "1:5:4"
    >         }
    >       },
    >       {
    >         "noteid": "2HUHA23PM",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HUHA23PM",
    >           "name": "6. Working with cross-matched surveys",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/6. Working with cross-matched surveys",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:1:50"
    >         }
    >       },
    >       {
    >         "noteid": "2HTER41AJ",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HTER41AJ",
    >           "name": "7. Good astrometric solutions via ML Random Forest classifier",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/7. Good astrometric solutions via ML Random Forest classifier",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:7:39"
    >         }
    >       },
    >       {
    >         "noteid": "2HRAFRQ55",
    >         "clear": {
    >           "status": "OK",
    >           "message": ""
    >         },
    >         "execute": {
    >           "id": "2HRAFRQ55",
    >           "name": "8. Tips and tricks",
    >           "path": "/Users/oovah5aiN9te6Cha/examples/8. Tips and tricks",
    >           "paragraphs": [
    >             ....
    >             ....
    >           ],
    >           "duration": "0:0:28"
    >         }
    >       }
    >     ],
    >     "duration": "1:17:27"
    >   }

    #
    # No clue as to what causes the parse errors, logged it as an issue.
    # https://github.com/wfau/gaia-dmp/issues/1120
    #

    #
    # Check the execution times.
    #

    jq '
        .notebooks[].execute | {name, duration}
        ' "/tmp/${username}-testall.json"

    >   {
    >     "name": "1. Start here",
    >     "duration": "0:0:40"
    >   }
    >   {
    >     "name": "2. Data holdings",
    >     "duration": "0:0:12"
    >   }
    >   {
    >     "name": "3. Source counts over the sky",
    >     "duration": "0:0:36"
    >   }
    >   {
    >     "name": "4. Mean proper motions over the sky",
    >     "duration": "0:0:55"
    >   }
    >   {
    >     "name": "5. Working with Gaia XP spectra",
    >     "duration": "1:5:4"
    >   }
    >   {
    >     "name": "6. Working with cross-matched surveys",
    >     "duration": "0:1:50"
    >   }
    >   {
    >     "name": "7. Good astrometric solutions via ML Random Forest classifier",
    >     "duration": "0:7:39"
    >   }
    >   {
    >     "name": "8. Tips and tricks",
    >     "duration": "0:0:28"
    >   }

    #
    # The spectra search takes over an hour.
    #

# -----------------------------------------------------
# Check the server logs for errors.
#[root@ansibler]

    #
    # Lots of errors in the server side logs.
    #

    ssh zeppelin \
        '
        grep "ERROR" "${HOME}/zeppelin/logs/zeppelin-interpreter-spark-'${username}'-'${username}'-$(whoami)-$(hostname).log"
        '

    >   ERROR [2023-02-09 16:24:50,043] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 26 on worker04: Container from a bad node: container_1675951226569_0001_01_000045 on host: worker04. Exit status: 137. Diagnostics: [2023-02-09 16:24:49.859]Container killed on request. Exit code is 137
    >   ERROR [2023-02-09 16:25:44,328] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 27 on worker02: Container from a bad node: container_1675951226569_0001_01_000046 on host: worker02. Exit status: 137. Diagnostics: [2023-02-09 16:25:43.976]Container killed on request. Exit code is 137
    >   ....
    >   ....
    >   ERROR [2023-02-09 16:37:52,342] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 32 on worker05: Executor heartbeat timed out after 124543 ms
    >   ERROR [2023-02-09 16:37:52,352] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 14 on worker05: Executor heartbeat timed out after 125722 ms
    >   ERROR [2023-02-09 16:37:52,354] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 37 on worker05: Executor heartbeat timed out after 124268 ms
    >   ERROR [2023-02-09 16:37:52,366] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 31 on worker02: Executor heartbeat timed out after 134233 ms
    >   ERROR [2023-02-09 16:39:52,272] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 42 on worker01: Executor heartbeat timed out after 125895 ms
    >   ERROR [2023-02-09 16:40:52,356] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logError]:73) - Lost executor 33 on worker04: Executor heartbeat timed out after 134081 ms
    >   ....
    >   ....
    >   ERROR [2023-02-09 17:25:06,369] ({rpc-server-4-1} TransportClient.java[operationComplete]:337) - Failed to send RPC RPC 7663707678650834553 to /10.10.3.176:54746: java.nio.channels.ClosedChannelException
    >   ERROR [2023-02-09 17:25:06,369] ({rpc-server-4-5} TransportClient.java[operationComplete]:337) - Failed to send RPC RPC 8288730622270622879 to /10.10.1.48:47600: java.nio.channels.ClosedChannelException
    >   ....
    >   ....


# -----------------------------------------------------
# Count specific matches.
#[root@ansibler]

    ssh zeppelin \
        '
        ln -s "${HOME}/zeppelin/logs/zeppelin-interpreter-spark-'${username}'-'${username}'-$(whoami)-$(hostname).log" "/tmp/spark-log"
        '

    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*$" \
            "/tmp/spark-log"
        '

    >   461


    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*Lost executor [0-9]* on worker[0-9]*.*$" \
            "/tmp/spark-log"
        '

    >   46

    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*Lost executor [0-9]* on worker[0-9]*: Container from a bad node.*$" \
            "/tmp/spark-log"
        '

    >   34


    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*Lost executor [0-9]* on worker[0-9]*: Container from a bad node.*Exit code is 137$" \
            "/tmp/spark-log"
        '

    >   34


    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*Lost executor [0-9]* on worker[0-9]*: Executor heartbeat timed out.*$" \
            "/tmp/spark-log"
        '

    >   12


    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*Failed to send RPC.*$" \
            "/tmp/spark-log"
        '

    >   415


    ssh zeppelin \
        '
        grep -c \
            "^ERROR.*Failed to send RPC.*.*ClosedChannelException$" \
            "/tmp/spark-log"
        '

    >   415

    #
    # Error messages logged as an issue.
    # https://github.com/wfau/gaia-dmp/issues/1121
    #

     34 * "ERROR [2023-02-09 16:25:44,328] .... Lost executor 27 on worker02: Container from a bad node: .... Exit code is 137"
     12 * "ERROR [2023-02-09 16:37:52,342] .... Lost executor 32 on worker05: Executor heartbeat timed out ...."
    415 * "ERROR [2023-02-09 17:25:06,369] .... Failed to send RPC .... java.nio.channels.ClosedChannelException"




