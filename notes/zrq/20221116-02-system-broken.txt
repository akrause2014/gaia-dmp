#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2022, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Notes on broken system status.

    Result:

        Work in progress ...


# -----------------------------------------------------
# -----------------------------------------------------
# Check which cloud is currently live.
#[user@desktop]

    ssh fedora@live.gaia-dmp.uk \
        '
        date
        hostname
        '

    >   Wed Nov 16 17:47:14 UTC 2022
    >   iris-gaia-blue-20221013-zeppelin


# -----------------------------------------------------
# -----------------------------------------------------
# Deploy everything.
#[root@ansibler]

    time \
        source /deployments/hadoop-yarn/bin/deploy.sh

    >   aglais:
    >     status:
    >       deployment:
    >         type: hadoop-yarn
    >         conf: zeppelin-54.86-spark-6.26.43
    >         name: iris-gaia-green-20221116
    >         date: 20221116T131654
    >         hostname: zeppelin.gaia-dmp.uk
    >     spec:
    >       openstack:
    >         cloud:
    >           base: arcus
    >           name: iris-gaia-green
    >   
    >   real	170m34.424s
    >   user	33m1.086s
    >   sys	6m45.956s


    #
    # Possibly the slowest deployment yet.
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Check live system notebooks.
#[....]


    #
    # Source counts example fails
    # https://dmp.gaia.ac.uk/#/notebook/2HBZQDEAW

    >   Settings
    >   FINISHED
    >   Took 0 sec. Last updated by DMorris at November 16 2022, 5:36:26 PM.

    >   Set the resolution level and define the query
    >   FINISHED
    >   Took 0 sec. Last updated by DMorris at November 16 2022, 5:36:26 PM.

    >   Plot up the results
    >   Py4JJavaError: An error occurred while calling o169.javaToPython.
    >   : org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:
    >   Exchange hashpartitioning(FLOOR((cast(source_id#5L as double) / 1.40737488355328E14))#181L, 200), ENSURE_REQUIREMENTS, [id=#213]
    >   +- *(1) HashAggregate(
    >           keys=[
    >               FLOOR(
    >                   (
    >                   cast(source_id#5L as double) / 1.40737488355328E14
    >                   )
    >               )
    >           AS FLOOR(
    >               (cast(source_id#5L as double) / 1.40737488355328E14))
    >               #181L
    >               ],
    >           functions=[
    >               partial_count(1)
    >               ],
    >           output=[
    >               FLOOR(
    >                   (cast(source_id#5L as double) / 1.40737488355328E14)
    >                   )
    >               #181L,
    >               count#183L
    >               ]
    >           )
    >      +- *(1) ColumnarToRow
    >         +- FileScan parquet gaiadr3.gaia_source[source_id#5L]
    >           Batched: true,
    >           DataFilters: [],
    >           Format: Parquet,
    >           Location: InMemoryFileIndex[file:/data/gaia/GDR3/GDR3_GAIASOURCE],
    >           PartitionFilters: [],
    >           PushedFilters: [],
    >           ReadSchema: struct<source_id:bigint>
    >   
    >   	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)
    >   	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:163)
    >   	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)
    >   	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)
    >       ....
    >       ....
    >   	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    >   	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    >   	at py4j.GatewayConnection.run(GatewayConnection.java:238)
    >   	at java.lang.Thread.run(Thread.java:748)
    >   Caused by: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
    >   This stopped SparkContext was created at:
    >   
    >   org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:939)
    >   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    >   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    >   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    >   ....
    >   ....
    >   org.apache.zeppelin.scheduler.Job.run(Job.java:172)
    >   org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)
    >   org.apache.zeppelin.scheduler.FIFOScheduler.lambda$runJobInScheduler$0(FIFOScheduler.java:42)
    >   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    >   
    >   The currently active SparkContext was created at:
    >   
    >   (No active SparkContext.)
    >   
    >   	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
    >   	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1506)
    >   	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.buildReaderWithPartitionValues(ParquetFileFormat.scala:231)
    >   	at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:407)
    >       ....
    >       ....
    >   	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:149)
    >   	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:166)
    >   	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
    >   	... 31 more
    >   
    >   (<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling o169.javaToPython.\n', JavaObject id=o174), <traceback object at 0x7f1aab0dc870>)
    >   ERROR
    >   Took 0 sec. Last updated by DMorris at November 16 2022, 5:36:26 PM.

# -----------------------------------------------------
# Check live system data.
#[fedora@zeppelin]

    ls /data/gaia/GDR3_2048/GDR3_2048_GAIASOURCE

    >   part-00000-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_00000.c000.snappy.parquet
    >   part-00001-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_00001.c000.snappy.parquet
    >   part-00002-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_00002.c000.snappy.parquet
    >   part-00003-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_00003.c000.snappy.parquet
    >   ....
    >   ....
    >   part-02044-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_02044.c000.snappy.parquet
    >   part-02045-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_02045.c000.snappy.parquet
    >   part-02046-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_02046.c000.snappy.parquet
    >   part-02047-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_02047.c000.snappy.parquet
    >   _SUCCESS


    md5sum /data/gaia/GDR3_2048/GDR3_2048_GAIASOURCE/part-00000-18ac60bc-42ce-42dd-ab5b-fc0027a56a2c_00000.c000.snappy.parquet | cut -f 1 -d ' '

    >   d5cf2f7995f164d2a47cd72c8c516160


# -----------------------------------------------------
# Restart Zeppelin ....
#[fedora@zeppelin]

    zeppelin-daemon.sh restart

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# -----------------------------------------------------
# Check live system notebooks.
#[....]

    #
    # Source counts example passes.
    # https://dmp.gaia.ac.uk/#/notebook/2HBZQDEAW

    #
    # Notebook works OK, but still has lots of warnings.
    # Crappy user experience.
    #

    >   WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:920: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_over(newcm(1.0))
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:921: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_under(bgcolor)
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:922: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. This has been deprecated since 3.3 and in 3.6, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = mpl.cm.get_cmap("viridis").copy()
    >     newcm.set_bad(badcolor)
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:211: MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax simultaneously is deprecated since 3.3 and will become an error two minor releases later. Please pass vmin/vmax directly to the norm when creating it.
    >     **kwds
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:543: UserWarning: 0.0 180.0 -180.0 180.0
    >     pmin / dtor, pmax / dtor, mmin / dtor, mmax / dtor
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:658: UserWarning: The interval between parallels is 30 deg -0.00'.
    >     vdeg, varcmin
    >   /usr/local/lib64/python3.7/site-packages/healpy/projaxes.py:666: UserWarning: The interval between meridians is 30 deg -0.00'.
    >     vdeg, varcmin



